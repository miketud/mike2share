# Structured RAG System Setup Guide

## System Architecture Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        CLIENT PC (Development)                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚Ä¢ Frontend (Next.js)        :3000                              ‚îÇ
‚îÇ  ‚Ä¢ Backend (FastAPI)         :8000                              ‚îÇ
‚îÇ  ‚Ä¢ PostgreSQL                :5432                              ‚îÇ
‚îÇ  ‚Ä¢ Code Editing                                                 ‚îÇ
‚îÇ  ‚Ä¢ Git Repository                                               ‚îÇ
‚îÇ  ‚Ä¢ Development Tools                                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                      ‚îÇ               ‚îÇ
                     Tailscale VPN or LAN
                      ‚îÇ               ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     WORKSTATION (Compute Only)                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚Ä¢ vLLM                      :8001                              ‚îÇ
‚îÇ  ‚Ä¢ Qdrant                    :6333                              ‚îÇ
‚îÇ  ‚Ä¢ Embedding Service         :8002                              ‚îÇ
‚îÇ  ‚Ä¢ Celery Worker             (background)                       ‚îÇ
‚îÇ  ‚Ä¢ Redis                     :6379                              ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚Ä¢ File Storage              ~/gpu-services/file_storage/       ‚îÇ
‚îÇ  ‚Ä¢ Model Storage             ~/gpu-services/models/             ‚îÇ
‚îÇ  ‚Ä¢ Vector Database           Qdrant                             ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚Ä¢ All GPU/CPU Tasks                                            ‚îÇ
‚îÇ  ‚Ä¢ No User Data Storage (except vectors)                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## PC (Client) Responsibilities

### 1. Setup and Configuration

```bash
# Run the bootstrap script to create project structure
./bootstrap-feb10.sh

# When prompted, enter your project name
# Example: rag-platform
```

### 2. Client-Side Services

```bash
# Start local PostgreSQL database
docker-compose up -d postgres

# Start local backend API
cd backend
./start.sh

# Start local frontend
cd frontend
pnpm dev
```

### 3. Client-Workstation Connectivity

```bash
# Configure workstation connection details in backend/.env
echo 'WORKSTATION_VLLM=http://WORKSTATION_IP:8001/v1' >> .env
echo 'WORKSTATION_QDRANT_HOST=WORKSTATION_IP' >> .env
echo 'WORKSTATION_EMBEDDING=http://WORKSTATION_IP:8002' >> .env
echo 'WORKSTATION_CELERY_BROKER=redis://WORKSTATION_IP:6379/0' >> .env
```

### 4. PC System Verification

```bash
# Check client system requirements
docker --version
node --version
python3 --version

# Verify client can reach workstation
ping WORKSTATION_IP
curl -X GET http://WORKSTATION_IP:8002/health
```

## üñ•Ô∏è Workstation Responsibilities

### 1. Prerequisites Check

```bash
# Check Docker with NVIDIA support
docker --version
docker info

# Check NVIDIA drivers
nvidia-smi
nvcc --version

# Check system resources
df -h  # Disk space
free -h  # RAM
```

### 2. Workstation Setup

```bash
# Create GPU services directory
mkdir -p ~/gpu-services
cd ~/gpu-services

# Create service directories
mkdir -p embedding-service celery-worker qdrant_data file_storage models
```

### 3. Workstation Services Configuration

```yaml
# ~/gpu-services/docker-compose.yml
version: "3.8"

services:
  vllm:
    image: vllm/vllm-openai:latest
    runtime: nvidia
    environment:
      - CUDA_VISIBLE_DEVICES=1,2
    command: >
      --model /models/gpt-oss-120b
      --tensor-parallel-size 2
      --host 0.0.0.0
      --port 8000
    ports:
      - "8001:8000"
    volumes:
      - /home/you/models:/models
    restart: unless-stopped

  embedding-service:
    build: ./embedding-service
    runtime: nvidia
    environment:
      - CUDA_VISIBLE_DEVICES=1
    ports:
      - "8002:8000"
    volumes:
      - /home/you/models:/models
    restart: unless-stopped

  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"
    volumes:
      - ./qdrant_data:/qdrant/storage
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    restart: unless-stopped

  celery-worker:
    build: ./celery-worker
    runtime: nvidia
    environment:
      - CUDA_VISIBLE_DEVICES=2
      - CELERY_BROKER_URL=redis://redis:6379/0
    depends_on:
      - redis
    volumes:
      - /home/you/models:/models
    restart: unless-stopped
```

### 4. Workstation File Storage Setup

```bash
# Create file storage directory
mkdir -p ~/gpu-services/file_storage

# Verify storage setup
ls -la ~/gpu-services/file_storage
```

### 5. Workstation Service Deployment

```bash
# Start all workstation services
cd ~/gpu-services
docker-compose up -d

# Verify services are running
docker-compose ps
```

## üîÑ Data Flow and Processing

### 1. File Upload Process

```
PC (Client) ‚Üí Upload File ‚Üí PC Backend (FastAPI)
           ‚Üì
PC Backend ‚Üí Send File Path to Workstation Storage
           ‚Üì
PC Backend ‚Üí Send Processing Request to Workstation Services
           ‚Üì
Workstation ‚Üí ALL Processing (Parse, Chunk, Embed, Store in Qdrant)
           ‚Üì
PC Backend ‚Üí Receive Results ‚Üí Store Metadata in PostgreSQL
```

### 2. Query Processing

```
PC (Client) ‚Üí User Query ‚Üí PC Backend
           ‚Üì
PC Backend ‚Üí Send Query to Workstation Embedding Service
           ‚Üì
Workstation ‚Üí Generate Query Vector ‚Üí Search Qdrant
           ‚Üì
Workstation ‚Üí Return Vector IDs ‚Üí PC Backend
           ‚Üì
PC Backend ‚Üí Get Chunk Metadata from PostgreSQL
           ‚Üì
PC Backend ‚Üí Build Context ‚Üí Send to Workstation LLM
           ‚Üì
Workstation ‚Üí Generate Answer ‚Üí Return to PC Backend
           ‚Üì
PC Backend ‚Üí Store Query Log in PostgreSQL
           ‚Üì
PC (Client) ‚Üí Display Results
```

## üõ†Ô∏è Workstation Service Implementation

### 1. Embedding Service

```bash
# Create embedding service directory
cd ~/gpu-services/embedding-service

# Create Dockerfile
FROM nvidia/cuda:11.8.0-runtime-ubuntu20.00

WORKDIR /app
RUN apt-get update && apt-get install -y python3 python3-pip
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
EXPOSE 8000
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

```txt
# requirements.txt
fastapi
sentence-transformers
pydantic
uvicorn
```

```python
# main.py
from fastapi import FastAPI
from sentence_transformers import SentenceTransformer
from pydantic import BaseModel

app = FastAPI()
model = SentenceTransformer('BAAI/bge-large-en-v1.5', device='cuda')

class EmbedRequest(BaseModel):
    texts: list[str]
    batch_size: int = 256

@app.post("/encode")
async def encode(request: EmbedRequest):
    embeddings = model.encode(
        request.texts,
        batch_size=request.batch_size,
        show_progress_bar=False,
        convert_to_tensor=True
    )
    return {
        "embeddings": embeddings.cpu().tolist(),
        "model": "bge-large-en-v1.5",
        "dimension": len(embeddings[0])
    }

@app.get("/health")
async def health():
    return {"status": "ready", "gpu": "cuda", "model_loaded": True}
```

### 2. Celery Worker

```bash
# Create celery worker directory
cd ~/gpu-services/celery-worker

# Create Dockerfile
FROM nvidia/cuda:11.8.0-runtime-ubuntu20.00

WORKDIR /app
RUN apt-get update && apt-get install -y python3 python3-pip
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
EXPOSE 8000
CMD ["celery", "-A", "tasks", "worker", "--loglevel=info"]
```

```txt
# requirements.txt
celery
redis
torch
transformers
axolotl
```

```python
# tasks.py
from celery import Celery

app = Celery('fine_tuning_tasks')
app.config_from_object({
    'broker_url': 'redis://redis:6379/0',
    'result_backend': 'redis://redis:6379/0',
    'task_serializer': 'json',
    'accept_content': ['json'],
    'result_serializer': 'json',
    'timezone': 'UTC',
    'enable_utc': True,
})

@app.task
def fine_tune_model():
    return "Fine-tuning task completed"
```

## üîç System Verification

### 1. PC Verification

```bash
# Test client connectivity
curl -X GET http://WORKSTATION_IP:8002/health
curl -X GET http://WORKSTATION_IP:6333/health

# Test database connectivity
psql -h localhost -U raguser -d ragdb
```

### 2. Workstation Verification

```bash
# Test workstation services
docker-compose ps

# Test individual service health
curl -X GET http://localhost:8002/health
curl -X GET http://localhost:6333/health

# Monitor GPU usage
nvidia-smi -l 1
```

## üßπ Maintenance and Cleanup

### 1. PC Maintenance

```bash
# Regular database checks
docker-compose ps postgres
psql -c "SELECT COUNT(*) FROM documents;"

# Client cleanup
docker-compose down
```

### 2. Workstation Maintenance

```bash
# Regular cleanup
docker image prune -a
docker container prune
docker volume prune

# Monitor resources
docker stats
nvidia-smi
df -h
```

## üìä Resource Management

### 1. GPU Resource Allocation

```bash
# Workstation GPU configuration
CUDA_VISIBLE_DEVICES=0,1,2  # Assign specific GPUs to services
```

### 2. Storage Management

```
Workstation Storage Structure:
~/gpu-services/
‚îú‚îÄ‚îÄ file_storage/        # Raw uploaded files
‚îú‚îÄ‚îÄ models/              # Model files
‚îú‚îÄ‚îÄ qdrant_data/         # Qdrant vector storage
‚îî‚îÄ‚îÄ embedding-service/   # Service code
```

## üö® Troubleshooting

### 1. Common Issues

```bash
# Docker GPU access
sudo apt-get install nvidia-container-toolkit
sudo systemctl restart docker

# Network connectivity
ping WORKSTATION_IP
telnet WORKSTATION_IP 8002

# Service health
docker-compose logs embedding-service
docker-compose logs vllm
```

### 2. Performance Optimization

```bash
# Monitor GPU usage
nvidia-smi -l 1

# Check resource usage
docker stats

# Optimize batch sizes
# Adjust batch_size in embedding requests
```

## ‚úÖ Best Practices

### 1. Security

- Keep sensitive data on PC, vectors on workstation
- Use secure network connections (VPN)
- Regular backup of PostgreSQL database

### 2. Performance

- Monitor GPU utilization
- Optimize batch processing
- Implement asynchronous file handling

### 3. Maintenance

- Regular system checks
- Backup model files
- Update Docker images periodically

## üìã Summary

### PC Responsibilities:

- ‚úÖ User interface and application logic
- ‚úÖ PostgreSQL database management
- ‚úÖ API orchestration
- ‚úÖ Network connectivity to workstation
- ‚úÖ Development and testing

### Workstation Responsibilities:

- ‚úÖ All GPU/CPU processing
- ‚úÖ File storage and management
- ‚úÖ Vector database (Qdrant)
- ‚úÖ Model storage and serving
- ‚úÖ Background task processing (Celery)

This architecture provides a clean separation where the PC handles development and user interaction while the workstation handles all compute-intensive tasks, making it efficient, scalable, and secure.
